{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1176357,"sourceType":"datasetVersion","datasetId":667852}],"dockerImageVersionId":30615,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport tensorflow\nfrom tensorflow import keras\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-09T22:15:36.456023Z","iopub.execute_input":"2023-12-09T22:15:36.456390Z","iopub.status.idle":"2023-12-09T22:15:54.310444Z","shell.execute_reply.started":"2023-12-09T22:15:36.456343Z","shell.execute_reply":"2023-12-09T22:15:54.309657Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\nimport os\nimport seaborn as sns\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input","metadata":{"execution":{"iopub.status.busy":"2023-12-09T22:15:54.312032Z","iopub.execute_input":"2023-12-09T22:15:54.312708Z","iopub.status.idle":"2023-12-09T22:15:54.998916Z","shell.execute_reply.started":"2023-12-09T22:15:54.312664Z","shell.execute_reply":"2023-12-09T22:15:54.998112Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))","metadata":{"execution":{"iopub.status.busy":"2023-12-09T22:15:55.000159Z","iopub.execute_input":"2023-12-09T22:15:55.000626Z","iopub.status.idle":"2023-12-09T22:15:55.939042Z","shell.execute_reply.started":"2023-12-09T22:15:55.000590Z","shell.execute_reply":"2023-12-09T22:15:55.937874Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Num GPUs Available:  2\n","output_type":"stream"}]},{"cell_type":"code","source":"train_images=[]\ntrain_labels=[]\nval_images=[]\nval_labels=[]\nrandom_seed=42","metadata":{"execution":{"iopub.status.busy":"2023-12-09T22:15:55.942162Z","iopub.execute_input":"2023-12-09T22:15:55.942577Z","iopub.status.idle":"2023-12-09T22:15:55.953386Z","shell.execute_reply.started":"2023-12-09T22:15:55.942548Z","shell.execute_reply":"2023-12-09T22:15:55.952587Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(os.listdir(\"/kaggle/input/animal-faces/afhq/train\"))","metadata":{"execution":{"iopub.status.busy":"2023-12-09T22:15:55.954492Z","iopub.execute_input":"2023-12-09T22:15:55.954812Z","iopub.status.idle":"2023-12-09T22:15:55.973578Z","shell.execute_reply.started":"2023-12-09T22:15:55.954786Z","shell.execute_reply":"2023-12-09T22:15:55.972762Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"['dog', 'wild', 'cat']\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dir = '/kaggle/input/animal-faces/afhq/train'\nvalid_dir = '/kaggle/input/animal-faces/afhq/val'","metadata":{"execution":{"iopub.status.busy":"2023-12-09T22:15:55.974579Z","iopub.execute_input":"2023-12-09T22:15:55.974855Z","iopub.status.idle":"2023-12-09T22:15:55.978753Z","shell.execute_reply.started":"2023-12-09T22:15:55.974830Z","shell.execute_reply":"2023-12-09T22:15:55.977904Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    preprocessing_function=preprocess_input\n)\n\nvalid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-09T22:15:55.980025Z","iopub.execute_input":"2023-12-09T22:15:55.980614Z","iopub.status.idle":"2023-12-09T22:15:55.989093Z","shell.execute_reply.started":"2023-12-09T22:15:55.980582Z","shell.execute_reply":"2023-12-09T22:15:55.988238Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# 훈련 데이터 제너레이터\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical'\n)\n\n# 검증 데이터 제너레이터\nvalid_generator = valid_datagen.flow_from_directory(\n    valid_dir,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical'\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T22:15:55.990149Z","iopub.execute_input":"2023-12-09T22:15:55.990556Z","iopub.status.idle":"2023-12-09T22:16:03.635272Z","shell.execute_reply.started":"2023-12-09T22:15:55.990530Z","shell.execute_reply":"2023-12-09T22:16:03.634433Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Found 14630 images belonging to 3 classes.\nFound 1500 images belonging to 3 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"base_model=VGG16(weights='imagenet',include_top=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T22:16:03.636604Z","iopub.execute_input":"2023-12-09T22:16:03.637337Z","iopub.status.idle":"2023-12-09T22:16:14.025099Z","shell.execute_reply.started":"2023-12-09T22:16:03.637296Z","shell.execute_reply":"2023-12-09T22:16:14.024193Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n553467096/553467096 [==============================] - 3s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"base_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-09T22:16:14.028894Z","iopub.execute_input":"2023-12-09T22:16:14.029212Z","iopub.status.idle":"2023-12-09T22:16:14.089415Z","shell.execute_reply.started":"2023-12-09T22:16:14.029177Z","shell.execute_reply":"2023-12-09T22:16:14.088512Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Model: \"vgg16\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n                                                                 \n block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n                                                                 \n block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n                                                                 \n block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n                                                                 \n block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n                                                                 \n block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n                                                                 \n block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n                                                                 \n block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n                                                                 \n block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n                                                                 \n block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n                                                                 \n block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n                                                                 \n block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n                                                                 \n flatten (Flatten)           (None, 25088)             0         \n                                                                 \n fc1 (Dense)                 (None, 4096)              102764544 \n                                                                 \n fc2 (Dense)                 (None, 4096)              16781312  \n                                                                 \n predictions (Dense)         (None, 1000)              4097000   \n                                                                 \n=================================================================\nTotal params: 138357544 (527.79 MB)\nTrainable params: 138357544 (527.79 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(base_model)\nmodel.add(Dense(3, activation='softmax'))\nfor layer in base_model.layers:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-12-09T22:16:14.090649Z","iopub.execute_input":"2023-12-09T22:16:14.090926Z","iopub.status.idle":"2023-12-09T22:16:14.200831Z","shell.execute_reply.started":"2023-12-09T22:16:14.090902Z","shell.execute_reply":"2023-12-09T22:16:14.199794Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-09T22:16:14.202137Z","iopub.execute_input":"2023-12-09T22:16:14.202478Z","iopub.status.idle":"2023-12-09T22:16:14.221587Z","shell.execute_reply.started":"2023-12-09T22:16:14.202449Z","shell.execute_reply":"2023-12-09T22:16:14.220660Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n vgg16 (Functional)          (None, 1000)              138357544 \n                                                                 \n dense (Dense)               (None, 3)                 3003      \n                                                                 \n=================================================================\nTotal params: 138360547 (527.80 MB)\nTrainable params: 3003 (11.73 KB)\nNon-trainable params: 138357544 (527.79 MB)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.optimizers import Adam\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2023-12-09T22:16:14.222869Z","iopub.execute_input":"2023-12-09T22:16:14.223209Z","iopub.status.idle":"2023-12-09T22:16:14.241682Z","shell.execute_reply.started":"2023-12-09T22:16:14.223183Z","shell.execute_reply":"2023-12-09T22:16:14.240677Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# model.fit(train_generator, epochs=10, validation_data=valid_generator)\nhistory = model.fit(train_generator, epochs=30, validation_data=valid_generator)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T22:16:14.242874Z","iopub.execute_input":"2023-12-09T22:16:14.243175Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/30\n458/458 [==============================] - 319s 663ms/step - loss: 0.9182 - accuracy: 0.9381 - val_loss: 0.7603 - val_accuracy: 0.9927\nEpoch 2/30\n458/458 [==============================] - 213s 465ms/step - loss: 0.6395 - accuracy: 0.9948 - val_loss: 0.5315 - val_accuracy: 0.9927\nEpoch 3/30\n458/458 [==============================] - 209s 457ms/step - loss: 0.4527 - accuracy: 0.9952 - val_loss: 0.3808 - val_accuracy: 0.9927\nEpoch 4/30\n458/458 [==============================] - 211s 459ms/step - loss: 0.3287 - accuracy: 0.9948 - val_loss: 0.2812 - val_accuracy: 0.9933\nEpoch 5/30\n458/458 [==============================] - 210s 458ms/step - loss: 0.2461 - accuracy: 0.9948 - val_loss: 0.2139 - val_accuracy: 0.9933\nEpoch 6/30\n458/458 [==============================] - 211s 460ms/step - loss: 0.1883 - accuracy: 0.9953 - val_loss: 0.1671 - val_accuracy: 0.9933\nEpoch 7/30\n458/458 [==============================] - 212s 463ms/step - loss: 0.1469 - accuracy: 0.9953 - val_loss: 0.1337 - val_accuracy: 0.9933\nEpoch 8/30\n458/458 [==============================] - 210s 458ms/step - loss: 0.1178 - accuracy: 0.9951 - val_loss: 0.1093 - val_accuracy: 0.9933\nEpoch 9/30\n458/458 [==============================] - 208s 454ms/step - loss: 0.0954 - accuracy: 0.9948 - val_loss: 0.0911 - val_accuracy: 0.9933\nEpoch 10/30\n458/458 [==============================] - 208s 453ms/step - loss: 0.0781 - accuracy: 0.9954 - val_loss: 0.0775 - val_accuracy: 0.9933\nEpoch 11/30\n458/458 [==============================] - 209s 457ms/step - loss: 0.0650 - accuracy: 0.9958 - val_loss: 0.0669 - val_accuracy: 0.9933\nEpoch 12/30\n458/458 [==============================] - 212s 463ms/step - loss: 0.0558 - accuracy: 0.9948 - val_loss: 0.0589 - val_accuracy: 0.9933\nEpoch 13/30\n458/458 [==============================] - 209s 455ms/step - loss: 0.0463 - accuracy: 0.9961 - val_loss: 0.0525 - val_accuracy: 0.9933\nEpoch 14/30\n458/458 [==============================] - 207s 452ms/step - loss: 0.0405 - accuracy: 0.9954 - val_loss: 0.0476 - val_accuracy: 0.9933\nEpoch 15/30\n458/458 [==============================] - 211s 461ms/step - loss: 0.0356 - accuracy: 0.9954 - val_loss: 0.0439 - val_accuracy: 0.9933\nEpoch 16/30\n173/458 [==========>...................] - ETA: 2:06 - loss: 0.0341 - accuracy: 0.9951","output_type":"stream"}]},{"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(valid_generator)\nprint(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(aaaaaaaaaaaaaaaaaa)#여기서 자동stop","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print('train data set')\n# train_cat_path='/kaggle/input/animal-faces/afhq/train/cat'\n# train_cat_img=[f for f in os.listdir(train_cat_path)]\n# print(f'고양이 사진: {len(train_cat_img)}개')\n\n# train_dog_path='/kaggle/input/animal-faces/afhq/train/dog'\n# train_dog_img=[f for f in os.listdir(train_dog_path)]\n# print(f'강아지 사진: {len(train_dog_img)}개')\n\n\n# train_wild_path='/kaggle/input/animal-faces/afhq/train/wild'\n# train_wild_img=[f for f in os.listdir(train_wild_path)]\n# print(f'다른동물 사진: {len(train_wild_img)}개')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# min_samples = min(len(train_cat_img), len(train_dog_img), len(train_wild_img))\n\n# # 각 클래스에서 최소 샘플 수만큼 랜덤하게 선택하여 데이터셋 구성\n# selected_cat_img = random.sample(train_cat_img, min_samples)\n# selected_dog_img = random.sample(train_dog_img, min_samples)\n# selected_wild_img = random.sample(train_wild_img, min_samples)\n\n# train_set=[]\n# for img_file in selected_cat_img:\n#     img_path = os.path.join(train_cat_path, img_file)\n#     img = image.load_img(img_path, target_size=(224, 224))\n#     x = image.img_to_array(img)\n#     x = preprocess_input(x)\n#     train_set.append((x,0))  # 0은 고양이에 해당하는 라벨\n\n# for img_file in selected_dog_img:\n#     img_path = os.path.join(train_dog_path, img_file)\n#     img = image.load_img(img_path, target_size=(224, 224))\n#     x = image.img_to_array(img)\n#     x = preprocess_input(x)\n#     train_set.append((x,1))  # 1은 강아지에 해당하는 라벨\n\n# for img_file in selected_wild_img:\n#     img_path = os.path.join(train_wild_path, img_file)\n#     img = image.load_img(img_path, target_size=(224, 224))\n#     x = image.img_to_array(img)\n#     x = preprocess_input(x)\n#     train_set.append((x,2))  # 2는 다른 동물에 해당하는 라벨\n\n# random.shuffle(train_set)\n# # 리스트를 NumPy 배열로 변환\n# train_images = np.array([item[0] for item in train_set])\n# train_labels = np.array([item[1] for item in train_set])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# num_samples_to_visualize = 5\n\n# # 랜덤하게 몇 개의 인덱스 선택\n# random_indices = np.random.choice(len(train_images), num_samples_to_visualize, replace=False)\n\n# # 선택된 이미지와 라벨 시각화\n# for i in random_indices:\n#     img = train_images[i]\n#     label = train_labels[i]\n\n#     # 시각화\n#     plt.figure(figsize=(2, 2))\n#     plt.imshow(img)\n#     plt.title(f\"Label: {label}\")\n#     plt.axis('off')\n#     plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(f'train_image : {len(train_images)}개')\n# print(f'train_label : {len(train_labels)}개')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print('validation data set')\n# valid_path='/kaggle/input/animal-faces/afhq/val'\n\n# valid_cat_path=os.path.join(valid_path, 'cat')\n# valid_cat_img=[f for f in os.listdir(valid_cat_path)]\n# print(f'고양이 사진: {len(valid_cat_img)}개')\n\n# valid_dog_path=os.path.join(valid_path, 'dog')\n# valid_dog_img=[f for f in os.listdir(valid_dog_path)]\n# print(f'강아지 사진: {len(valid_dog_img)}개')\n\n# valid_wild_path=os.path.join(valid_path, 'wild')\n# valid_wild_img=[f for f in os.listdir(valid_wild_path)]\n# print(f'다른동물 사진: {len(valid_wild_img)}개')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# valid_set=[]\n# for img_file in valid_cat_img:\n#     img_path = os.path.join(valid_cat_path, img_file)\n#     img = image.load_img(img_path, target_size=(224, 224))\n#     x = image.img_to_array(img)\n#     x = preprocess_input(x)\n#     valid_set.append((x,0))  # 0은 고양이에 해당하는 라벨\n\n# for img_file in valid_dog_img:\n#     img_path = os.path.join(valid_dog_path, img_file)\n#     img = image.load_img(img_path, target_size=(224, 224))\n#     x = image.img_to_array(img)\n#     x = preprocess_input(x)\n#     valid_set.append((x,1))  # 1은 강아지에 해당하는 라벨\n\n# for img_file in valid_wild_img:\n#     img_path = os.path.join(valid_wild_path, img_file)\n#     img = image.load_img(img_path, target_size=(224, 224))\n#     x = image.img_to_array(img)\n#     x = preprocess_input(x)\n#     valid_set.append((x,2))  # 2는 다른 동물에 해당하는 라벨\n\n# random.shuffle(train_set)\n# # 리스트를 NumPy 배열로 변환\n# valid_images = np.array([item[0] for item in valid_set])\n# valid_labels = np.array([item[1] for item in valid_set])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(len(valid_images))\n# print(len(valid_labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# random_indices = np.random.choice(len(valid_images), num_samples_to_visualize, replace=False)\n\n# # 선택된 이미지와 라벨 시각화\n# for i in random_indices:\n#     img = valid_images[i]\n#     label = valid_labels[i]\n\n#     # 시각화\n#     plt.figure(figsize=(2, 2))\n#     plt.imshow(img)\n#     plt.title(f\"Label: {label}\")\n#     plt.axis('off')\n#     plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# base_model=VGG16(weights='imagenet',include_top=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# base_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = Sequential()\n# model.add(base_model)\n# model.add(Dense(3, activation='softmax'))\n# for layer in base_model.layers:\n#     layer.trainable = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from keras.preprocessing.image import ImageDataGenerator\n\n# datagen = ImageDataGenerator(\n#     rotation_range=20,\n#     width_shift_range=0.2,\n#     height_shift_range=0.2,\n#     shear_range=0.2,\n#     zoom_range=0.2,\n#     horizontal_flip=True,\n#     fill_mode='nearest',\n#     preprocessing_function=preprocess_input\n# )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from keras.optimizers import Adam\n# model.compile(optimizer=Adam(lr=0.001), \n#               loss='sparse_categorical_crossentropy', metrics=['accuracy', 'val_loss'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history = model.fit(train_images, train_labels, validation_data=(valid_images, valid_labels), epochs=10, batch_size=16)\n# test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n# print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}