{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1176357,"sourceType":"datasetVersion","datasetId":667852}],"dockerImageVersionId":30615,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport tensorflow\nfrom tensorflow import keras\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-09T21:04:46.365529Z","iopub.execute_input":"2023-12-09T21:04:46.366439Z","iopub.status.idle":"2023-12-09T21:04:57.171541Z","shell.execute_reply.started":"2023-12-09T21:04:46.366394Z","shell.execute_reply":"2023-12-09T21:04:57.170461Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\nimport os\nimport seaborn as sns\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input","metadata":{"execution":{"iopub.status.busy":"2023-12-09T21:04:57.173319Z","iopub.execute_input":"2023-12-09T21:04:57.175052Z","iopub.status.idle":"2023-12-09T21:04:58.235261Z","shell.execute_reply.started":"2023-12-09T21:04:57.175004Z","shell.execute_reply":"2023-12-09T21:04:58.233991Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_images=[]\ntrain_labels=[]\nval_images=[]\nval_labels=[]\nrandom_seed=42","metadata":{"execution":{"iopub.status.busy":"2023-12-09T21:04:58.236971Z","iopub.execute_input":"2023-12-09T21:04:58.237355Z","iopub.status.idle":"2023-12-09T21:04:58.242901Z","shell.execute_reply.started":"2023-12-09T21:04:58.237321Z","shell.execute_reply":"2023-12-09T21:04:58.241590Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(os.listdir(\"/kaggle/input/animal-faces/afhq/train\"))","metadata":{"execution":{"iopub.status.busy":"2023-12-09T21:04:58.246926Z","iopub.execute_input":"2023-12-09T21:04:58.247476Z","iopub.status.idle":"2023-12-09T21:04:58.269706Z","shell.execute_reply.started":"2023-12-09T21:04:58.247427Z","shell.execute_reply":"2023-12-09T21:04:58.268822Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"['dog', 'wild', 'cat']\n","output_type":"stream"}]},{"cell_type":"code","source":"print('train data set')\ntrain_cat_path='/kaggle/input/animal-faces/afhq/train/cat'\ntrain_cat_img=[f for f in os.listdir(train_cat_path)]\nprint(f'고양이 사진: {len(train_cat_img)}개')\n\ntrain_dog_path='/kaggle/input/animal-faces/afhq/train/dog'\ntrain_dog_img=[f for f in os.listdir(train_dog_path)]\nprint(f'강아지 사진: {len(train_dog_img)}개')\n\n\ntrain_wild_path='/kaggle/input/animal-faces/afhq/train/wild'\ntrain_wild_img=[f for f in os.listdir(train_wild_path)]\nprint(f'다른동물 사진: {len(train_wild_img)}개')","metadata":{"execution":{"iopub.status.busy":"2023-12-09T21:04:58.271389Z","iopub.execute_input":"2023-12-09T21:04:58.272093Z","iopub.status.idle":"2023-12-09T21:04:58.534988Z","shell.execute_reply.started":"2023-12-09T21:04:58.272054Z","shell.execute_reply":"2023-12-09T21:04:58.533803Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"train data set\n고양이 사진: 5153개\n강아지 사진: 4739개\n다른동물 사진: 4738개\n","output_type":"stream"}]},{"cell_type":"code","source":"min_samples = min(len(train_cat_img), len(train_dog_img), len(train_wild_img))\n\n# 각 클래스에서 최소 샘플 수만큼 랜덤하게 선택하여 데이터셋 구성\nselected_cat_img = random.sample(train_cat_img, min_samples)\nselected_dog_img = random.sample(train_dog_img, min_samples)\nselected_wild_img = random.sample(train_wild_img, min_samples)\n\ntrain_set=[]\nfor img_file in selected_cat_img:\n    img_path = os.path.join(train_cat_path, img_file)\n    img = image.load_img(img_path, target_size=(224, 224))\n    x = image.img_to_array(img)\n    x = preprocess_input(x)\n    train_set.append((x,0))  # 0은 고양이에 해당하는 라벨\n\nfor img_file in selected_dog_img:\n    img_path = os.path.join(train_dog_path, img_file)\n    img = image.load_img(img_path, target_size=(224, 224))\n    x = image.img_to_array(img)\n    x = preprocess_input(x)\n    train_set.append((x,1))  # 1은 강아지에 해당하는 라벨\n\nfor img_file in selected_wild_img:\n    img_path = os.path.join(train_wild_path, img_file)\n    img = image.load_img(img_path, target_size=(224, 224))\n    x = image.img_to_array(img)\n    x = preprocess_input(x)\n    train_set.append((x,2))  # 2는 다른 동물에 해당하는 라벨\n\nrandom.shuffle(train_set)\n# 리스트를 NumPy 배열로 변환\ntrain_images = np.array([item[0] for item in train_set])\ntrain_labels = np.array([item[1] for item in train_set])","metadata":{"execution":{"iopub.status.busy":"2023-12-09T21:04:58.536592Z","iopub.execute_input":"2023-12-09T21:04:58.537194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_samples_to_visualize = 5\n\n# 랜덤하게 몇 개의 인덱스 선택\nrandom_indices = np.random.choice(len(train_images), num_samples_to_visualize, replace=False)\n\n# 선택된 이미지와 라벨 시각화\nfor i in random_indices:\n    img = train_images[i]\n    label = train_labels[i]\n\n    # 시각화\n    plt.figure(figsize=(2, 2))\n    plt.imshow(img)\n    plt.title(f\"Label: {label}\")\n    plt.axis('off')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'train_image : {len(train_images)}개')\nprint(f'train_label : {len(train_labels)}개')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('validation data set')\nvalid_path='/kaggle/input/animal-faces/afhq/val'\n\nvalid_cat_path=os.path.join(valid_path, 'cat')\nvalid_cat_img=[f for f in os.listdir(valid_cat_path)]\nprint(f'고양이 사진: {len(valid_cat_img)}개')\n\nvalid_dog_path=os.path.join(valid_path, 'dog')\nvalid_dog_img=[f for f in os.listdir(valid_dog_path)]\nprint(f'강아지 사진: {len(valid_dog_img)}개')\n\nvalid_wild_path=os.path.join(valid_path, 'wild')\nvalid_wild_img=[f for f in os.listdir(valid_wild_path)]\nprint(f'다른동물 사진: {len(valid_wild_img)}개')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_set=[]\nfor img_file in valid_cat_img:\n    img_path = os.path.join(valid_cat_path, img_file)\n    img = image.load_img(img_path, target_size=(224, 224))\n    x = image.img_to_array(img)\n    x = preprocess_input(x)\n    valid_set.append((x,0))  # 0은 고양이에 해당하는 라벨\n\nfor img_file in valid_dog_img:\n    img_path = os.path.join(valid_dog_path, img_file)\n    img = image.load_img(img_path, target_size=(224, 224))\n    x = image.img_to_array(img)\n    x = preprocess_input(x)\n    valid_set.append((x,1))  # 1은 강아지에 해당하는 라벨\n\nfor img_file in valid_wild_img:\n    img_path = os.path.join(valid_wild_path, img_file)\n    img = image.load_img(img_path, target_size=(224, 224))\n    x = image.img_to_array(img)\n    x = preprocess_input(x)\n    valid_set.append((x,2))  # 2는 다른 동물에 해당하는 라벨\n\nrandom.shuffle(train_set)\n# 리스트를 NumPy 배열로 변환\nvalid_images = np.array([item[0] for item in valid_set])\nvalid_labels = np.array([item[1] for item in valid_set])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(valid_images))\nprint(len(valid_labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_indices = np.random.choice(len(valid_images), num_samples_to_visualize, replace=False)\n\n# 선택된 이미지와 라벨 시각화\nfor i in random_indices:\n    img = valid_images[i]\n    label = valid_labels[i]\n\n    # 시각화\n    plt.figure(figsize=(2, 2))\n    plt.imshow(img)\n    plt.title(f\"Label: {label}\")\n    plt.axis('off')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model=VGG16(weights='imagenet',include_top=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(base_model)\nmodel.add(Dense(3, activation='softmax'))\nfor layer in base_model.layers:\n    layer.trainable = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.optimizers import Adam\nmodel.compile(optimizer=Adam(lr=0.001), \n              loss='sparse_categorical_crossentropy', metrics=['accuracy', 'val_loss'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_images, train_labels, validation_data=(valid_images, valid_labels), epochs=10, batch_size=32)\ntest_loss, test_accuracy = model.evaluate(test_images, test_labels)\nprint(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}